<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>chebyshev | Parth Thaker</title>
    <link>https://parththaker.github.io/tags/chebyshev/</link>
      <atom:link href="https://parththaker.github.io/tags/chebyshev/index.xml" rel="self" type="application/rss+xml" />
    <description>chebyshev</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Â© 2020 Parth Thaker</copyright><lastBuildDate>Sat, 01 Jul 2017 12:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>chebyshev</title>
      <link>https://parththaker.github.io/tags/chebyshev/</link>
    </image>
    
    <item>
      <title>Basic look over Chebyshev Polynomials</title>
      <link>https://parththaker.github.io/post/chebyshev/</link>
      <pubDate>Sat, 01 Jul 2017 12:00:00 +0000</pubDate>
      <guid>https://parththaker.github.io/post/chebyshev/</guid>
      <description>&lt;p&gt;Though I myself am doubtful about a lot of explanations here. I&amp;rsquo;ll remember and explain whatever I can.&lt;/p&gt;
&lt;p&gt;Lets first start with the basics, The chebyshev polynomial of degree $n$ is denoted by $T_n(x)$ and given by the formula,&lt;/p&gt;
&lt;p&gt;$$
\begin{equation}T_n(x) = cos(n cos^{-1}(x))\end{equation}$$&lt;/p&gt;
&lt;p&gt;They form the recursive relation given by,
$$T_n(x) = cos(n cos^{-1}(x))$$&lt;/p&gt;
&lt;p&gt;$$T_{n+1} (x) = 2 x T_n(x) - T_{n-1}$$&lt;/p&gt;
&lt;p&gt;Extrema of Chebyshev polynomial $T_n$ are given in the form of,&lt;/p&gt;
&lt;p&gt;$$ x_k = cos\left(\frac{2k-1}{2n}\pi\right),\ \ \ \ \ k=1,2,\dots, n$$&lt;/p&gt;
&lt;p&gt;They look something like this&amp;hellip;&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;../../img/chebyshev.png&#34; alt=&#34; Chebyshev &#34;&gt;&lt;/p&gt;
&lt;p&gt;the extrema of Chebyshev polynomials are distributed over the entire range of the approximation and have alternating values of plus or minus unity. These characteristics make Chebyshev polynomials an ideal basis for approximating functions Its a well known fact that Chebyshev function approximation is as good as it gets.&lt;/p&gt;
&lt;p&gt;It is known that the mean squared error for a function fitting is minimum for a minimax function. But evaluation of a minimax polynomial is computationally expensive. Chebyshev polynomial fitting is quite close to minimax polynomial fitting and is computationally much cheaper.&lt;/p&gt;
&lt;p&gt;$$f= \sum_{i=0}^M c_iT_i$$&lt;/p&gt;
&lt;p&gt;where $T_i$ is the Chebyshev polynomial of order starting from i. {$c_i$} indicate the chebyshev coefficients. Normally the chebyshev coefficients falls off exponentially. Partly i used to think it was because that the chebyshev polynomials of order $i$ had a $2^i$ term as the coefficient of $x^i$. But the prof said that it was because of that the chebyshev coefficients dropping rate is directly proportional to the Region Of Convergence.&lt;/p&gt;
&lt;p&gt;In order to apply stable Chebyshev fitting the Taylor expansion of the function should have a bounded reminder term. Other than this Chebyshev can be normally shrunk in the number of terms used for the polynomial fitting with a bounded error which is normally the sum of magnitudes of all the coefficients of the neglected terms. This is because the max value of the polynomials is +/- 1 and because the chebyshev coefficients die out much easily this error is bounded with a very small value when you neglect the higher order terms.&lt;/p&gt;
&lt;p&gt;A very good thing about chebyshev polynomails i liked was the intuition or a way to look at it. It can be looked as though it takes the points on the real line from -1 to 1 and maps them to a unit circle of radius 1 and center 0 and then back to the real line. If u think about it  this mapping sort of elongates the function and makes the curves much less steeper. Thus it can be seen as to why the Chebyshev fitting requires much less order polynomial then its counter Taylor expansion, though both are  polynomial fittings.&lt;/p&gt;
&lt;p&gt;When looked at the recurrence equation of chebyshev polynomials we have,&lt;/p&gt;
&lt;p&gt;$$T_{n+1} = 2xT_{n} -T_{n-1}$$&lt;/p&gt;
&lt;p&gt;Analyzing this equation we get that the Chebyshev polynomial derived from this can only lead to stable solutions within +1 and -1. Analysis of the roots of characteristic equations makes it evident.&lt;/p&gt;
&lt;p&gt;Chebyshev does better than Fourier in almost all cases except for periodic functions. Where Fourier can leave Cheby in dust. But both of them do worse for functions with non differentiable peaks or valleys within the interval of consideration. It is advised to break the functions at such peaks and then do Chebyshev fitting on separate parts for better results.&lt;/p&gt;
&lt;h2 id=&#34;license&#34;&gt;License&lt;/h2&gt;
&lt;p&gt;Copyright 2017 
&lt;a href=&#34;https://parththaker.github.io/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;Parth Thaker&lt;/a&gt;
.&lt;/p&gt;
&lt;p&gt;Released under the 
&lt;a href=&#34;https://github.com/gcushen/hugo-academic/blob/master/LICENSE.md&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MIT&lt;/a&gt;
 license.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
