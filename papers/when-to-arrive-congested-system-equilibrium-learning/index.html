<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/39b0e861c537f507-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/6801a04e29283989.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/c7863c883e44cb4e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-a9151074ccb83ac8.js"/><script src="/_next/static/chunks/4bd1b696-d4d5eb693d0a7af9.js" async=""></script><script src="/_next/static/chunks/684-6102a85c1a7a49eb.js" async=""></script><script src="/_next/static/chunks/main-app-54ea5828605064c9.js" async=""></script><script src="/_next/static/chunks/729-0ae0020d02b338de.js" async=""></script><script src="/_next/static/chunks/63-604b46d13fd30a34.js" async=""></script><script src="/_next/static/chunks/app/papers/%5Bslug%5D/page-7d3e6ccfb45e5478.js" async=""></script><meta name="next-size-adjust" content=""/><script type="application/ld+json">{"@context":"https://schema.org","@type":"Person","name":"Parth K. Thaker","jobTitle":"AI Research Engineer","worksFor":{"@type":"Organization","name":"Intuitive Surgical","url":"https://www.intuitive.com"},"alumniOf":[{"@type":"EducationalOrganization","name":"Arizona State University","url":"https://www.asu.edu"},{"@type":"EducationalOrganization","name":"Indian Institute of Technology Madras","url":"https://www.iitm.ac.in"}],"url":"https://parththaker.github.io","image":"https://parththaker.github.io/profile_photo.png","sameAs":["https://www.linkedin.com/in/parththaker1/","https://twitter.com/ParthKThaker","https://github.com/parththaker"],"knowsAbout":["Graph Theory","Nonconvex Optimization","Bandit Learning","Reinforcement Learning","Machine Learning","Artificial Intelligence","Electrical Engineering"],"hasCredential":{"@type":"EducationalOccupationalCredential","name":"Ph.D. in Electrical Engineering","credentialCategory":"degree"}}</script><title>Parth K. Thaker - AI Research Engineer | Graph Theory &amp; Optimization</title><meta name="description" content="AI Research Engineer at Intuitive Surgical. Ph.D. in Electrical Engineering from ASU. Specializing in nonconvex optimization, graph theory, bandit learning, and secure LLM workflows."/><meta name="author" content="Parth K. Thaker"/><meta name="keywords" content="Parth Thaker,AI Research Engineer,Graph Theory,Nonconvex Optimization,Bandit Learning,Reinforcement Learning,Machine Learning,Intuitive Surgical,Arizona State University,ASU,IIT Madras,Electrical Engineering,LLM,Secure AI,Research Portfolio"/><meta name="creator" content="Parth K. Thaker"/><meta name="publisher" content="Parth K. Thaker"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://parththaker.github.io/"/><meta name="google-site-verification" content="google-site-verification-code-here"/><meta property="og:title" content="Parth K. Thaker - AI Research Engineer | Graph Theory &amp; Optimization"/><meta property="og:description" content="AI Research Engineer at Intuitive Surgical. Ph.D. in Electrical Engineering from ASU. Specializing in nonconvex optimization, graph theory, bandit learning, and secure LLM workflows."/><meta property="og:url" content="https://parththaker.github.io/"/><meta property="og:site_name" content="Parth K. Thaker"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://parththaker.github.io/profile_photo.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Parth K. Thaker - AI Research Engineer"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@ParthKThaker"/><meta name="twitter:title" content="Parth K. Thaker - AI Research Engineer | Graph Theory &amp; Optimization"/><meta name="twitter:description" content="AI Research Engineer at Intuitive Surgical. Ph.D. in Electrical Engineering from ASU. Specializing in nonconvex optimization, graph theory, bandit learning, and secure LLM workflows."/><meta name="twitter:image" content="https://parththaker.github.io/profile_photo.png"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_e8ce0c __variable_96cdd1 antialiased font-sans"><div hidden=""><!--$--><!--/$--></div><div class="min-h-screen relative bg-gradient-to-br from-slate-50 via-blue-50 to-indigo-50"><div style="background:linear-gradient(135deg, #3b82f6, #6366f1);box-shadow:0 0 10px rgba(59, 130, 246, 0.5);transition:transform 0.1s ease" class="jsx-aa1a58a7acb30062 fixed w-3 h-3 pointer-events-none z-[10000] rounded-full"></div><canvas class="fixed inset-0 pointer-events-none z-0" style="opacity:0.6"></canvas><nav class="relative z-50 border-b border-slate-200/50 bg-white/80 backdrop-blur-md sticky top-0"><div class="max-w-7xl mx-auto px-6 py-4"><div class="flex justify-between items-center"><a class="text-2xl font-bold gradient-text" href="/">Parth K. Thaker</a><div class="flex gap-8"><a class="relative group" href="/papers/"><span class="text-blue-600 font-medium">Papers</span><div class="absolute -bottom-1 left-0 w-full h-0.5 bg-gradient-to-r from-blue-500 to-indigo-500"></div></a><a class="relative group" href="/blogs/"><span class="text-slate-700 hover:text-orange-600 transition-colors duration-300 font-medium">Blog</span><div class="absolute -bottom-1 left-0 w-0 h-0.5 bg-gradient-to-r from-orange-500 to-red-500 group-hover:w-full transition-all duration-300"></div></a><a class="relative group" href="/hobbies/"><span class="text-slate-700 hover:text-green-600 transition-colors duration-300 font-medium">Hobbies</span><div class="absolute -bottom-1 left-0 w-0 h-0.5 bg-gradient-to-r from-green-500 to-emerald-500 group-hover:w-full transition-all duration-300"></div></a></div></div></div></nav><div class="relative z-10 max-w-5xl mx-auto px-6 py-12"><div class="network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200 mb-8"><div class="space-y-6"><div><h1 class="text-4xl font-bold gradient-text mb-4">When to arrive in a congested system: Achieving equilibrium via learning algorithm</h1><div class="flex flex-wrap items-center gap-x-6 gap-y-2 mb-6 text-sm"><div class="text-slate-500">P Thaker</div><div class="text-slate-500">December 2016</div><div class="text-slate-500">IEEE ISIT 2017</div></div><div class="flex flex-wrap gap-2 mb-6"><span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium">Game Theory</span><span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium">Learning Algorithms</span><span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium">Nash Equilibrium</span><span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium">Resource Allocation</span><span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium">Congestion Control</span></div><div class="flex flex-wrap gap-4 pt-4 border-t border-slate-200"><a href="https://doi.org/10.1109/ISIT.2017.8007066" class="flex items-center gap-2 text-blue-600 hover:text-blue-700 font-medium transition-colors" target="_blank" rel="noopener noreferrer"><div class="w-2 h-2 bg-blue-500 rounded-full"></div>DOI</a></div></div></div></div><div class="network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200 mb-8"><h2 class="text-2xl font-bold gradient-text mb-4">Abstract</h2><p class="text-slate-700 leading-relaxed text-lg">We consider a strategic problem where multiple players compete to access a shared server platform that operates intermittently, switching between ON and OFF periods. Each player incurs costs to sample the server state and receives payoffs inversely proportional to the number of simultaneously connected players. We propose a distributed randomized learning algorithm that enables players to minimize sensing costs while converging to a unique fixed point that constitutes a Nash equilibrium. The work addresses applications in competitive WiFi sensing and competition for user attention in social networks.</p></div><div class="network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200 mb-8"><h2 class="text-2xl font-bold gradient-text mb-4">What Excited Me</h2><p class="text-slate-700 leading-relaxed text-lg">This early work showcases the foundations of my fascination with strategic learning in competitive environments! What excites me most is how it captures the fundamental tension between exploration and competition - players want to find opportunities quickly but don&#x27;t want to compete with too many others once they find them. The intermittent server model is brilliant because it reflects so many real-world scenarios: WiFi hotspots, social media posting times, even stock market opportunities. The distributed learning algorithm is particularly clever because each player learns independently yet the system converges to a globally stable solution. It&#x27;s game theory meets machine learning in a way that&#x27;s both mathematically elegant and practically relevant. This work laid the groundwork for my later interest in multi-agent systems and strategic decision-making under uncertainty!</p></div><div class="network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200"><div class="prose prose-lg prose-slate max-w-none prose-headings:gradient-text prose-h1:text-4xl prose-h2:text-3xl prose-h3:text-2xl prose-h4:text-xl prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline"><div><!-- # When to arrive in a congested system: Achieving equilibrium via learning algorithm -->
<h2>Problem Formulation</h2>
<h3>Strategic Congestion Game</h3>
<p>The paper addresses a fundamental strategic problem in resource allocation where:</p>
<ul>
<li><strong>Multiple players</strong> compete for access to a shared resource</li>
<li><strong>Intermittent availability</strong>: Server alternates between ON and OFF periods</li>
<li><strong>Sensing costs</strong>: Players incur costs to determine server state</li>
<li><strong>Congestion effects</strong>: Payoffs decrease with the number of simultaneous users</li>
</ul>
<h3>Real-World Motivation</h3>
<p>This framework captures numerous practical scenarios:</p>
<ul>
<li><strong>WiFi sensing</strong>: Devices competing to detect and connect to available networks</li>
<li><strong>Social media</strong>: Users timing posts to maximize attention and engagement</li>
<li><strong>Network access</strong>: Clients competing for limited bandwidth or processing resources</li>
<li><strong>Market timing</strong>: Traders seeking optimal entry points in volatile markets</li>
</ul>
<h2>Mathematical Framework</h2>
<h3>Player Objectives</h3>
<p>Each player faces a fundamental trade-off:</p>
<ul>
<li><strong>Early arrival</strong>: Higher chance of accessing the resource when it becomes available</li>
<li><strong>Congestion avoidance</strong>: Fewer competitors means higher individual payoffs</li>
<li><strong>Cost minimization</strong>: Reducing the frequency and expense of sensing operations</li>
</ul>
<h3>Payoff Structure</h3>
<ul>
<li><strong>Inverse relationship</strong>: Payoff ∝ 1/(number of simultaneous players)</li>
<li><strong>Timing sensitivity</strong>: Rewards for early detection of ON periods</li>
<li><strong>Cost considerations</strong>: Sensing frequency affects overall utility</li>
</ul>
<h2>Learning Algorithm Design</h2>
<h3>Distributed Randomized Learning</h3>
<p>The proposed algorithm features:</p>
<ul>
<li><strong>No central coordination</strong>: Each player operates independently</li>
<li><strong>Randomized sampling</strong>: Stochastic timing decisions to avoid predictable patterns</li>
<li><strong>Adaptive behavior</strong>: Learning from past experiences and outcomes</li>
<li><strong>Cost-aware optimization</strong>: Balancing sensing frequency with expected rewards</li>
</ul>
<h3>Key Algorithmic Properties</h3>
<ul>
<li><strong>Convergence guarantee</strong>: Provably converges to a unique fixed point</li>
<li><strong>Distributed implementation</strong>: No need for communication between players</li>
<li><strong>Robust to player entry/exit</strong>: Handles dynamic player populations</li>
<li><strong>Computationally efficient</strong>: Simple update rules suitable for real-time deployment</li>
</ul>
<h2>Theoretical Contributions</h2>
<h3>1. Nash Equilibrium Characterization</h3>
<ul>
<li><strong>Unique fixed point</strong>: Proved existence and uniqueness of equilibrium</li>
<li><strong>Strategic stability</strong>: No player has incentive to unilaterally deviate</li>
<li><strong>Global optimality</strong>: Fixed point achieves desirable system-wide properties</li>
</ul>
<h3>2. Convergence Analysis</h3>
<ul>
<li><strong>Theoretical guarantees</strong>: Mathematical proof of algorithm convergence</li>
<li><strong>Rate of convergence</strong>: Analysis of how quickly equilibrium is reached</li>
<li><strong>Stability properties</strong>: Robustness to small perturbations and noise</li>
</ul>
<h3>3. Selfish Tradeoffs</h3>
<ul>
<li><strong>Individual rationality</strong>: Each player optimizes their own utility</li>
<li><strong>Social efficiency</strong>: Analysis of system-wide performance at equilibrium</li>
<li><strong>Price of anarchy</strong>: Comparison between selfish and socially optimal outcomes</li>
</ul>
<h2>Applications and Impact</h2>
<h3>1. Competitive WiFi Sensing</h3>
<ul>
<li><strong>Device coordination</strong>: Smart phones and IoT devices optimizing network discovery</li>
<li><strong>Energy efficiency</strong>: Minimizing battery drain from frequent scanning</li>
<li><strong>Network load balancing</strong>: Distributing connection attempts across time</li>
</ul>
<h3>2. Social Network Dynamics</h3>
<ul>
<li><strong>Optimal posting times</strong>: Users learning when to share content for maximum engagement</li>
<li><strong>Attention economy</strong>: Competition for limited user attention spans</li>
<li><strong>Platform optimization</strong>: Understanding user behavior patterns</li>
</ul>
<h3>3. Resource Allocation Systems</h3>
<ul>
<li><strong>Server access</strong>: Clients timing requests to avoid congestion</li>
<li><strong>Computing resources</strong>: Distributed systems optimizing resource utilization</li>
<li><strong>Service queues</strong>: Strategic arrival timing in queueing systems</li>
</ul>
<h2>Technical Innovation</h2>
<h3>Game-Theoretic Learning</h3>
<ul>
<li><strong>Strategic learning</strong>: Players learn optimal strategies in competitive environments</li>
<li><strong>Equilibrium seeking</strong>: Algorithm design that naturally leads to stable outcomes</li>
<li><strong>Distributed decision making</strong>: No central planner required</li>
</ul>
<h3>Algorithmic Design Principles</h3>
<ul>
<li><strong>Simplicity</strong>: Easy-to-implement update rules</li>
<li><strong>Robustness</strong>: Performance maintained under various conditions</li>
<li><strong>Scalability</strong>: Handles large numbers of players efficiently</li>
</ul>
<h2>Broader Implications</h2>
<h3>Strategic Machine Learning</h3>
<p>This work contributes to the growing field of <strong>strategic machine learning</strong> where:</p>
<ul>
<li>Learning algorithms must account for strategic behavior of participants</li>
<li>Equilibrium analysis becomes crucial for understanding system behavior</li>
<li>Game theory provides tools for algorithm design and analysis</li>
</ul>
<h3>Multi-Agent Systems</h3>
<p>The research provides insights for:</p>
<ul>
<li><strong>Coordination without communication</strong>: Achieving global objectives through local actions</li>
<li><strong>Emergent behavior</strong>: How simple individual rules lead to complex system dynamics</li>
<li><strong>Robust distributed algorithms</strong>: Systems that work despite individual player strategies</li>
</ul>
<h2>Connection to Later Research</h2>
<p>This early work established foundations for several research directions:</p>
<ul>
<li><strong>Multi-agent learning</strong>: Later explored in multi-agent search and bandit problems</li>
<li><strong>Strategic behavior</strong>: Understanding how agents optimize in competitive environments</li>
<li><strong>Distributed optimization</strong>: Algorithms that converge without central coordination</li>
</ul>
<p>The emphasis on <strong>practical applications</strong> and <strong>real-world constraints</strong> (costs, intermittent availability) foreshadows the practical focus evident in later research on autonomous systems and robotics.</p>
<h2>Mathematical Elegance</h2>
<p>The beauty of this work lies in its mathematical structure:</p>
<ul>
<li><strong>Clean formulation</strong>: Complex real-world problems reduced to tractable mathematical models</li>
<li><strong>Convergence guarantees</strong>: Rigorous theoretical analysis supporting practical algorithms</li>
<li><strong>Universal principles</strong>: Framework applicable across diverse application domains</li>
</ul>
<p>This research demonstrates how fundamental theoretical insights in game theory and learning can address practical problems in distributed systems and strategic decision-making.</p></div></div></div></div></div><!--$--><!--/$--><script src="/_next/static/chunks/webpack-a9151074ccb83ac8.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n5:I[9665,[],\"OutletBoundary\"]\n8:I[4911,[],\"AsyncMetadataOutlet\"]\na:I[9665,[],\"ViewportBoundary\"]\nc:I[9665,[],\"MetadataBoundary\"]\ne:I[6614,[],\"\"]\n:HL[\"/_next/static/media/39b0e861c537f507-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/6801a04e29283989.css\",\"style\"]\n:HL[\"/_next/static/css/c7863c883e44cb4e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"cqZnD12rOwdqgUHXP0F3h\",\"p\":\"\",\"c\":[\"\",\"papers\",\"when-to-arrive-congested-system-equilibrium-learning\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"papers\",{\"children\":[[\"slug\",\"when-to-arrive-congested-system-equilibrium-learning\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/6801a04e29283989.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/c7863c883e44cb4e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"Parth K. Thaker\\\",\\\"jobTitle\\\":\\\"AI Research Engineer\\\",\\\"worksFor\\\":{\\\"@type\\\":\\\"Organization\\\",\\\"name\\\":\\\"Intuitive Surgical\\\",\\\"url\\\":\\\"https://www.intuitive.com\\\"},\\\"alumniOf\\\":[{\\\"@type\\\":\\\"EducationalOrganization\\\",\\\"name\\\":\\\"Arizona State University\\\",\\\"url\\\":\\\"https://www.asu.edu\\\"},{\\\"@type\\\":\\\"EducationalOrganization\\\",\\\"name\\\":\\\"Indian Institute of Technology Madras\\\",\\\"url\\\":\\\"https://www.iitm.ac.in\\\"}],\\\"url\\\":\\\"https://parththaker.github.io\\\",\\\"image\\\":\\\"https://parththaker.github.io/profile_photo.png\\\",\\\"sameAs\\\":[\\\"https://www.linkedin.com/in/parththaker1/\\\",\\\"https://twitter.com/ParthKThaker\\\",\\\"https://github.com/parththaker\\\"],\\\"knowsAbout\\\":[\\\"Graph Theory\\\",\\\"Nonconvex Optimization\\\",\\\"Bandit Learning\\\",\\\"Reinforcement Learning\\\",\\\"Machine Learning\\\",\\\"Artificial Intelligence\\\",\\\"Electrical Engineering\\\"],\\\"hasCredential\\\":{\\\"@type\\\":\\\"EducationalOccupationalCredential\\\",\\\"name\\\":\\\"Ph.D. in Electrical Engineering\\\",\\\"credentialCategory\\\":\\\"degree\\\"}}\"}}]}],[\"$\",\"body\",null,{\"className\":\"__variable_e8ce0c __variable_96cdd1 antialiased font-sans\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}]]}],{\"children\":[\"papers\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"when-to-arrive-congested-system-equilibrium-learning\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L4\",null,[\"$\",\"$L5\",null,{\"children\":[\"$L6\",\"$L7\",[\"$\",\"$L8\",null,{\"promise\":\"$@9\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"7Kp57ssE3WMH4Cw3u84Nbv\",{\"children\":[[\"$\",\"$La\",null,{\"children\":\"$Lb\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$e\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"f:\"$Sreact.suspense\"\n10:I[4911,[],\"AsyncMetadata\"]\nd:[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$f\",null,{\"fallback\":null,\"children\":[\"$\",\"$L10\",null,{\"promise\":\"$@11\"}]}]}]\n7:null\n"])</script><script>self.__next_f.push([1,"12:I[8694,[\"729\",\"static/chunks/729-0ae0020d02b338de.js\",\"63\",\"static/chunks/63-604b46d13fd30a34.js\",\"248\",\"static/chunks/app/papers/%5Bslug%5D/page-7d3e6ccfb45e5478.js\"],\"default\"]\n13:I[449,[\"729\",\"static/chunks/729-0ae0020d02b338de.js\",\"63\",\"static/chunks/63-604b46d13fd30a34.js\",\"248\",\"static/chunks/app/papers/%5Bslug%5D/page-7d3e6ccfb45e5478.js\"],\"default\"]\n14:I[6874,[\"729\",\"static/chunks/729-0ae0020d02b338de.js\",\"63\",\"static/chunks/63-604b46d13fd30a34.js\",\"248\",\"static/chunks/app/papers/%5Bslug%5D/page-7d3e6ccfb45e5478.js\"],\"\"]\n15:T1de5,"])</script><script>self.__next_f.push([1,"\u003c!-- # When to arrive in a congested system: Achieving equilibrium via learning algorithm --\u003e\n\u003ch2\u003eProblem Formulation\u003c/h2\u003e\n\u003ch3\u003eStrategic Congestion Game\u003c/h3\u003e\n\u003cp\u003eThe paper addresses a fundamental strategic problem in resource allocation where:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMultiple players\u003c/strong\u003e compete for access to a shared resource\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eIntermittent availability\u003c/strong\u003e: Server alternates between ON and OFF periods\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSensing costs\u003c/strong\u003e: Players incur costs to determine server state\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCongestion effects\u003c/strong\u003e: Payoffs decrease with the number of simultaneous users\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eReal-World Motivation\u003c/h3\u003e\n\u003cp\u003eThis framework captures numerous practical scenarios:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eWiFi sensing\u003c/strong\u003e: Devices competing to detect and connect to available networks\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSocial media\u003c/strong\u003e: Users timing posts to maximize attention and engagement\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNetwork access\u003c/strong\u003e: Clients competing for limited bandwidth or processing resources\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMarket timing\u003c/strong\u003e: Traders seeking optimal entry points in volatile markets\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eMathematical Framework\u003c/h2\u003e\n\u003ch3\u003ePlayer Objectives\u003c/h3\u003e\n\u003cp\u003eEach player faces a fundamental trade-off:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eEarly arrival\u003c/strong\u003e: Higher chance of accessing the resource when it becomes available\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCongestion avoidance\u003c/strong\u003e: Fewer competitors means higher individual payoffs\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCost minimization\u003c/strong\u003e: Reducing the frequency and expense of sensing operations\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003ePayoff Structure\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eInverse relationship\u003c/strong\u003e: Payoff ∝ 1/(number of simultaneous players)\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTiming sensitivity\u003c/strong\u003e: Rewards for early detection of ON periods\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCost considerations\u003c/strong\u003e: Sensing frequency affects overall utility\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eLearning Algorithm Design\u003c/h2\u003e\n\u003ch3\u003eDistributed Randomized Learning\u003c/h3\u003e\n\u003cp\u003eThe proposed algorithm features:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eNo central coordination\u003c/strong\u003e: Each player operates independently\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRandomized sampling\u003c/strong\u003e: Stochastic timing decisions to avoid predictable patterns\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAdaptive behavior\u003c/strong\u003e: Learning from past experiences and outcomes\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCost-aware optimization\u003c/strong\u003e: Balancing sensing frequency with expected rewards\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eKey Algorithmic Properties\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eConvergence guarantee\u003c/strong\u003e: Provably converges to a unique fixed point\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDistributed implementation\u003c/strong\u003e: No need for communication between players\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRobust to player entry/exit\u003c/strong\u003e: Handles dynamic player populations\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eComputationally efficient\u003c/strong\u003e: Simple update rules suitable for real-time deployment\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eTheoretical Contributions\u003c/h2\u003e\n\u003ch3\u003e1. Nash Equilibrium Characterization\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eUnique fixed point\u003c/strong\u003e: Proved existence and uniqueness of equilibrium\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStrategic stability\u003c/strong\u003e: No player has incentive to unilaterally deviate\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eGlobal optimality\u003c/strong\u003e: Fixed point achieves desirable system-wide properties\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2. Convergence Analysis\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTheoretical guarantees\u003c/strong\u003e: Mathematical proof of algorithm convergence\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRate of convergence\u003c/strong\u003e: Analysis of how quickly equilibrium is reached\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStability properties\u003c/strong\u003e: Robustness to small perturbations and noise\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e3. Selfish Tradeoffs\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eIndividual rationality\u003c/strong\u003e: Each player optimizes their own utility\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSocial efficiency\u003c/strong\u003e: Analysis of system-wide performance at equilibrium\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePrice of anarchy\u003c/strong\u003e: Comparison between selfish and socially optimal outcomes\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eApplications and Impact\u003c/h2\u003e\n\u003ch3\u003e1. Competitive WiFi Sensing\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eDevice coordination\u003c/strong\u003e: Smart phones and IoT devices optimizing network discovery\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEnergy efficiency\u003c/strong\u003e: Minimizing battery drain from frequent scanning\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNetwork load balancing\u003c/strong\u003e: Distributing connection attempts across time\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2. Social Network Dynamics\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOptimal posting times\u003c/strong\u003e: Users learning when to share content for maximum engagement\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAttention economy\u003c/strong\u003e: Competition for limited user attention spans\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePlatform optimization\u003c/strong\u003e: Understanding user behavior patterns\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e3. Resource Allocation Systems\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eServer access\u003c/strong\u003e: Clients timing requests to avoid congestion\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eComputing resources\u003c/strong\u003e: Distributed systems optimizing resource utilization\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eService queues\u003c/strong\u003e: Strategic arrival timing in queueing systems\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eTechnical Innovation\u003c/h2\u003e\n\u003ch3\u003eGame-Theoretic Learning\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eStrategic learning\u003c/strong\u003e: Players learn optimal strategies in competitive environments\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEquilibrium seeking\u003c/strong\u003e: Algorithm design that naturally leads to stable outcomes\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDistributed decision making\u003c/strong\u003e: No central planner required\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eAlgorithmic Design Principles\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSimplicity\u003c/strong\u003e: Easy-to-implement update rules\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRobustness\u003c/strong\u003e: Performance maintained under various conditions\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eScalability\u003c/strong\u003e: Handles large numbers of players efficiently\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eBroader Implications\u003c/h2\u003e\n\u003ch3\u003eStrategic Machine Learning\u003c/h3\u003e\n\u003cp\u003eThis work contributes to the growing field of \u003cstrong\u003estrategic machine learning\u003c/strong\u003e where:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eLearning algorithms must account for strategic behavior of participants\u003c/li\u003e\n\u003cli\u003eEquilibrium analysis becomes crucial for understanding system behavior\u003c/li\u003e\n\u003cli\u003eGame theory provides tools for algorithm design and analysis\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eMulti-Agent Systems\u003c/h3\u003e\n\u003cp\u003eThe research provides insights for:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eCoordination without communication\u003c/strong\u003e: Achieving global objectives through local actions\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEmergent behavior\u003c/strong\u003e: How simple individual rules lead to complex system dynamics\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRobust distributed algorithms\u003c/strong\u003e: Systems that work despite individual player strategies\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eConnection to Later Research\u003c/h2\u003e\n\u003cp\u003eThis early work established foundations for several research directions:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMulti-agent learning\u003c/strong\u003e: Later explored in multi-agent search and bandit problems\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eStrategic behavior\u003c/strong\u003e: Understanding how agents optimize in competitive environments\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDistributed optimization\u003c/strong\u003e: Algorithms that converge without central coordination\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThe emphasis on \u003cstrong\u003epractical applications\u003c/strong\u003e and \u003cstrong\u003ereal-world constraints\u003c/strong\u003e (costs, intermittent availability) foreshadows the practical focus evident in later research on autonomous systems and robotics.\u003c/p\u003e\n\u003ch2\u003eMathematical Elegance\u003c/h2\u003e\n\u003cp\u003eThe beauty of this work lies in its mathematical structure:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eClean formulation\u003c/strong\u003e: Complex real-world problems reduced to tractable mathematical models\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eConvergence guarantees\u003c/strong\u003e: Rigorous theoretical analysis supporting practical algorithms\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eUniversal principles\u003c/strong\u003e: Framework applicable across diverse application domains\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis research demonstrates how fundamental theoretical insights in game theory and learning can address practical problems in distributed systems and strategic decision-making.\u003c/p\u003e"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"min-h-screen relative bg-gradient-to-br from-slate-50 via-blue-50 to-indigo-50\",\"children\":[[\"$\",\"$L12\",null,{}],[\"$\",\"$L13\",null,{}],[\"$\",\"nav\",null,{\"className\":\"relative z-50 border-b border-slate-200/50 bg-white/80 backdrop-blur-md sticky top-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto px-6 py-4\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex justify-between items-center\",\"children\":[[\"$\",\"$L14\",null,{\"href\":\"/\",\"className\":\"text-2xl font-bold gradient-text\",\"children\":\"Parth K. Thaker\"}],[\"$\",\"div\",null,{\"className\":\"flex gap-8\",\"children\":[[\"$\",\"$L14\",null,{\"href\":\"/papers\",\"className\":\"relative group\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-blue-600 font-medium\",\"children\":\"Papers\"}],[\"$\",\"div\",null,{\"className\":\"absolute -bottom-1 left-0 w-full h-0.5 bg-gradient-to-r from-blue-500 to-indigo-500\"}]]}],[\"$\",\"$L14\",null,{\"href\":\"/blogs\",\"className\":\"relative group\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-slate-700 hover:text-orange-600 transition-colors duration-300 font-medium\",\"children\":\"Blog\"}],[\"$\",\"div\",null,{\"className\":\"absolute -bottom-1 left-0 w-0 h-0.5 bg-gradient-to-r from-orange-500 to-red-500 group-hover:w-full transition-all duration-300\"}]]}],[\"$\",\"$L14\",null,{\"href\":\"/hobbies\",\"className\":\"relative group\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-slate-700 hover:text-green-600 transition-colors duration-300 font-medium\",\"children\":\"Hobbies\"}],[\"$\",\"div\",null,{\"className\":\"absolute -bottom-1 left-0 w-0 h-0.5 bg-gradient-to-r from-green-500 to-emerald-500 group-hover:w-full transition-all duration-300\"}]]}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"relative z-10 max-w-5xl mx-auto px-6 py-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200 mb-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-6\",\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold gradient-text mb-4\",\"children\":\"When to arrive in a congested system: Achieving equilibrium via learning algorithm\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-x-6 gap-y-2 mb-6 text-sm\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-slate-500\",\"children\":\"P Thaker\"}],[\"$\",\"div\",null,{\"className\":\"text-slate-500\",\"children\":\"December 2016\"}],[\"$\",\"div\",null,{\"className\":\"text-slate-500\",\"children\":\"IEEE ISIT 2017\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-6\",\"children\":[[\"$\",\"span\",\"Game Theory\",{\"className\":\"px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium\",\"children\":\"Game Theory\"}],[\"$\",\"span\",\"Learning Algorithms\",{\"className\":\"px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium\",\"children\":\"Learning Algorithms\"}],[\"$\",\"span\",\"Nash Equilibrium\",{\"className\":\"px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium\",\"children\":\"Nash Equilibrium\"}],[\"$\",\"span\",\"Resource Allocation\",{\"className\":\"px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium\",\"children\":\"Resource Allocation\"}],[\"$\",\"span\",\"Congestion Control\",{\"className\":\"px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium\",\"children\":\"Congestion Control\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-4 pt-4 border-t border-slate-200\",\"children\":[\"$undefined\",[\"$\",\"a\",null,{\"href\":\"https://doi.org/10.1109/ISIT.2017.8007066\",\"className\":\"flex items-center gap-2 text-blue-600 hover:text-blue-700 font-medium transition-colors\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-2 h-2 bg-blue-500 rounded-full\"}],\"DOI\"]}],\"$undefined\",\"$undefined\",\"$undefined\",\"$undefined\"]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200 mb-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold gradient-text mb-4\",\"children\":\"Abstract\"}],[\"$\",\"p\",null,{\"className\":\"text-slate-700 leading-relaxed text-lg\",\"children\":\"We consider a strategic problem where multiple players compete to access a shared server platform that operates intermittently, switching between ON and OFF periods. Each player incurs costs to sample the server state and receives payoffs inversely proportional to the number of simultaneously connected players. We propose a distributed randomized learning algorithm that enables players to minimize sensing costs while converging to a unique fixed point that constitutes a Nash equilibrium. The work addresses applications in competitive WiFi sensing and competition for user attention in social networks.\"}]]}],[\"$\",\"div\",null,{\"className\":\"network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200 mb-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold gradient-text mb-4\",\"children\":\"What Excited Me\"}],[\"$\",\"p\",null,{\"className\":\"text-slate-700 leading-relaxed text-lg\",\"children\":\"This early work showcases the foundations of my fascination with strategic learning in competitive environments! What excites me most is how it captures the fundamental tension between exploration and competition - players want to find opportunities quickly but don't want to compete with too many others once they find them. The intermittent server model is brilliant because it reflects so many real-world scenarios: WiFi hotspots, social media posting times, even stock market opportunities. The distributed learning algorithm is particularly clever because each player learns independently yet the system converges to a globally stable solution. It's game theory meets machine learning in a way that's both mathematically elegant and practically relevant. This work laid the groundwork for my later interest in multi-agent systems and strategic decision-making under uncertainty!\"}]]}],\"$undefined\",\"$undefined\",[\"$\",\"div\",null,{\"className\":\"network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200\",\"children\":[\"$\",\"div\",null,{\"className\":\"prose prose-lg prose-slate max-w-none prose-headings:gradient-text prose-h1:text-4xl prose-h2:text-3xl prose-h3:text-2xl prose-h4:text-xl prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$15\"}}]}]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"b:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n6:null\n"])</script><script>self.__next_f.push([1,"9:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Parth K. Thaker - AI Research Engineer | Graph Theory \u0026 Optimization\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"AI Research Engineer at Intuitive Surgical. Ph.D. in Electrical Engineering from ASU. Specializing in nonconvex optimization, graph theory, bandit learning, and secure LLM workflows.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Parth K. Thaker\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"Parth Thaker,AI Research Engineer,Graph Theory,Nonconvex Optimization,Bandit Learning,Reinforcement Learning,Machine Learning,Intuitive Surgical,Arizona State University,ASU,IIT Madras,Electrical Engineering,LLM,Secure AI,Research Portfolio\"}],[\"$\",\"meta\",\"4\",{\"name\":\"creator\",\"content\":\"Parth K. Thaker\"}],[\"$\",\"meta\",\"5\",{\"name\":\"publisher\",\"content\":\"Parth K. Thaker\"}],[\"$\",\"meta\",\"6\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"7\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"8\",{\"rel\":\"canonical\",\"href\":\"https://parththaker.github.io/\"}],[\"$\",\"meta\",\"9\",{\"name\":\"google-site-verification\",\"content\":\"google-site-verification-code-here\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:title\",\"content\":\"Parth K. Thaker - AI Research Engineer | Graph Theory \u0026 Optimization\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:description\",\"content\":\"AI Research Engineer at Intuitive Surgical. Ph.D. in Electrical Engineering from ASU. Specializing in nonconvex optimization, graph theory, bandit learning, and secure LLM workflows.\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:url\",\"content\":\"https://parththaker.github.io/\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:site_name\",\"content\":\"Parth K. Thaker\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:image\",\"content\":\"https://parththaker.github.io/profile_photo.png\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"18\",{\"property\":\"og:image:alt\",\"content\":\"Parth K. Thaker - AI Research Engineer\"}],[\"$\",\"meta\",\"19\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"21\",{\"name\":\"twitter:creator\",\"content\":\"@ParthKThaker\"}],[\"$\",\"meta\",\"22\",{\"name\":\"twitter:title\",\"content\":\"Parth K. Thaker - AI Research Engineer | Graph Theory \u0026 Optimization\"}],[\"$\",\"meta\",\"23\",{\"name\":\"twitter:description\",\"content\":\"AI Research Engineer at Intuitive Surgical. Ph.D. in Electrical Engineering from ASU. Specializing in nonconvex optimization, graph theory, bandit learning, and secure LLM workflows.\"}],[\"$\",\"meta\",\"24\",{\"name\":\"twitter:image\",\"content\":\"https://parththaker.github.io/profile_photo.png\"}],[\"$\",\"link\",\"25\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"11:{\"metadata\":\"$9:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>