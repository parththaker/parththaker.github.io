<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1"/><link rel="preload" href="/_next/static/media/39b0e861c537f507-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="preload" href="/_next/static/media/e4af272ccee01ff0-s.p.woff2" as="font" crossorigin="" type="font/woff2"/><link rel="stylesheet" href="/_next/static/css/6801a04e29283989.css" data-precedence="next"/><link rel="stylesheet" href="/_next/static/css/c7863c883e44cb4e.css" data-precedence="next"/><link rel="preload" as="script" fetchPriority="low" href="/_next/static/chunks/webpack-a9151074ccb83ac8.js"/><script src="/_next/static/chunks/4bd1b696-d4d5eb693d0a7af9.js" async=""></script><script src="/_next/static/chunks/684-6102a85c1a7a49eb.js" async=""></script><script src="/_next/static/chunks/main-app-54ea5828605064c9.js" async=""></script><script src="/_next/static/chunks/729-0ae0020d02b338de.js" async=""></script><script src="/_next/static/chunks/63-604b46d13fd30a34.js" async=""></script><script src="/_next/static/chunks/app/papers/%5Bslug%5D/page-7d3e6ccfb45e5478.js" async=""></script><meta name="next-size-adjust" content=""/><script type="application/ld+json">{"@context":"https://schema.org","@type":"Person","name":"Parth K. Thaker","jobTitle":"AI Research Engineer","worksFor":{"@type":"Organization","name":"Intuitive Surgical","url":"https://www.intuitive.com"},"alumniOf":[{"@type":"EducationalOrganization","name":"Arizona State University","url":"https://www.asu.edu"},{"@type":"EducationalOrganization","name":"Indian Institute of Technology Madras","url":"https://www.iitm.ac.in"}],"url":"https://parththaker.github.io","image":"https://parththaker.github.io/profile_photo.png","sameAs":["https://www.linkedin.com/in/parththaker1/","https://twitter.com/ParthKThaker","https://github.com/parththaker"],"knowsAbout":["Graph Theory","Nonconvex Optimization","Bandit Learning","Reinforcement Learning","Machine Learning","Artificial Intelligence","Electrical Engineering"],"hasCredential":{"@type":"EducationalOccupationalCredential","name":"Ph.D. in Electrical Engineering","credentialCategory":"degree"}}</script><title>Parth K. Thaker - AI Research Engineer | Graph Theory &amp; Optimization</title><meta name="description" content="AI Research Engineer at Intuitive Surgical. Ph.D. in Electrical Engineering from ASU. Specializing in nonconvex optimization, graph theory, bandit learning, and secure LLM workflows."/><meta name="author" content="Parth K. Thaker"/><meta name="keywords" content="Parth Thaker,AI Research Engineer,Graph Theory,Nonconvex Optimization,Bandit Learning,Reinforcement Learning,Machine Learning,Intuitive Surgical,Arizona State University,ASU,IIT Madras,Electrical Engineering,LLM,Secure AI,Research Portfolio"/><meta name="creator" content="Parth K. Thaker"/><meta name="publisher" content="Parth K. Thaker"/><meta name="robots" content="index, follow"/><meta name="googlebot" content="index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1"/><link rel="canonical" href="https://parththaker.github.io/"/><meta name="google-site-verification" content="vR0MHUqGDsFvNBkYnX5muEopmvKabsrcthb-7WDj6nI"/><meta property="og:title" content="Parth K. Thaker - AI Research Engineer | Graph Theory &amp; Optimization"/><meta property="og:description" content="AI Research Engineer at Intuitive Surgical. Ph.D. in Electrical Engineering from ASU. Specializing in nonconvex optimization, graph theory, bandit learning, and secure LLM workflows."/><meta property="og:url" content="https://parththaker.github.io/"/><meta property="og:site_name" content="Parth K. Thaker"/><meta property="og:locale" content="en_US"/><meta property="og:image" content="https://parththaker.github.io/profile_photo.png"/><meta property="og:image:width" content="1200"/><meta property="og:image:height" content="630"/><meta property="og:image:alt" content="Parth K. Thaker - AI Research Engineer"/><meta property="og:type" content="website"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:creator" content="@ParthKThaker"/><meta name="twitter:title" content="Parth K. Thaker - AI Research Engineer | Graph Theory &amp; Optimization"/><meta name="twitter:description" content="AI Research Engineer at Intuitive Surgical. Ph.D. in Electrical Engineering from ASU. Specializing in nonconvex optimization, graph theory, bandit learning, and secure LLM workflows."/><meta name="twitter:image" content="https://parththaker.github.io/profile_photo.png"/><link rel="icon" href="/favicon.ico" type="image/x-icon" sizes="16x16"/><script>document.querySelectorAll('body link[rel="icon"], body link[rel="apple-touch-icon"]').forEach(el => document.head.appendChild(el))</script><script src="/_next/static/chunks/polyfills-42372ed130431b0a.js" noModule=""></script></head><body class="__variable_e8ce0c __variable_96cdd1 antialiased font-sans"><div hidden=""><!--$--><!--/$--></div><div class="min-h-screen relative bg-gradient-to-br from-slate-50 via-blue-50 to-indigo-50"><div style="background:linear-gradient(135deg, #3b82f6, #6366f1);box-shadow:0 0 10px rgba(59, 130, 246, 0.5);transition:transform 0.1s ease" class="jsx-aa1a58a7acb30062 fixed w-3 h-3 pointer-events-none z-[10000] rounded-full"></div><canvas class="fixed inset-0 pointer-events-none z-0" style="opacity:0.6"></canvas><nav class="relative z-50 border-b border-slate-200/50 bg-white/80 backdrop-blur-md sticky top-0"><div class="max-w-7xl mx-auto px-6 py-4"><div class="flex justify-between items-center"><a class="text-2xl font-bold gradient-text" href="/">Parth K. Thaker</a><div class="flex gap-8"><a class="relative group" href="/papers/"><span class="text-blue-600 font-medium">Papers</span><div class="absolute -bottom-1 left-0 w-full h-0.5 bg-gradient-to-r from-blue-500 to-indigo-500"></div></a><a class="relative group" href="/blogs/"><span class="text-slate-700 hover:text-orange-600 transition-colors duration-300 font-medium">Blog</span><div class="absolute -bottom-1 left-0 w-0 h-0.5 bg-gradient-to-r from-orange-500 to-red-500 group-hover:w-full transition-all duration-300"></div></a><a class="relative group" href="/hobbies/"><span class="text-slate-700 hover:text-green-600 transition-colors duration-300 font-medium">Hobbies</span><div class="absolute -bottom-1 left-0 w-0 h-0.5 bg-gradient-to-r from-green-500 to-emerald-500 group-hover:w-full transition-all duration-300"></div></a></div></div></div></nav><div class="relative z-10 max-w-5xl mx-auto px-6 py-12"><div class="network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200 mb-8"><div class="space-y-6"><div><h1 class="text-4xl font-bold gradient-text mb-4">Bandit-based multi-agent search under noisy observations</h1><div class="flex flex-wrap items-center gap-x-6 gap-y-2 mb-6 text-sm"><div class="text-slate-500">P Thaker, S Di Cairano, A P Vinod</div><div class="text-slate-500">June 2023</div><div class="text-slate-500">IFAC 2023</div></div><div class="flex flex-wrap gap-2 mb-6"><span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium">Multi-armed Bandits</span><span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium">Multi-agent Systems</span><span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium">Autonomous Search</span><span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium">Robotics</span><span class="px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium">Noise Robustness</span></div><div class="flex flex-wrap gap-4 pt-4 border-t border-slate-200"><a href="https://doi.org/10.1016/j.ifacol.2023.10.1377" class="flex items-center gap-2 text-blue-600 hover:text-blue-700 font-medium transition-colors" target="_blank" rel="noopener noreferrer"><div class="w-2 h-2 bg-blue-500 rounded-full"></div>DOI</a></div></div></div></div><div class="network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200 mb-8"><h2 class="text-2xl font-bold gradient-text mb-4">Abstract</h2><p class="text-slate-700 leading-relaxed text-lg">We address autonomous search using teams of multiple agents, requiring tractable coordination strategies that can lower the time to identify interesting areas in the search environment, lower the costs/energy usage by the search agents during movement and sensing, and be resilient to the noise present in the sensed data due to the use of low-cost and low-weight sensors. We propose a data-driven, multi-agent search algorithm to achieve these goals using the framework of thresholding multi-armed bandits. The algorithm includes finite upper bounds on the time taken to complete the search, on the time taken to label all interesting cells, and on the economic costs incurred during the search.</p></div><div class="network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200 mb-8"><h2 class="text-2xl font-bold gradient-text mb-4">What Excited Me</h2><p class="text-slate-700 leading-relaxed text-lg">This paper hits the sweet spot between theory and practice that I absolutely love! What excites me most is how it tackles real-world constraints that make autonomous systems actually deployable - noisy sensors, energy budgets, and coordination overhead. The genius lies in translating the classical multi-armed bandit framework to handle multiple agents simultaneously searching under uncertainty. The thresholding approach is particularly clever because it reflects how search missions actually work: you don&#x27;t need to find the absolute best locations, just ones that are &#x27;good enough&#x27; above some threshold. The finite upper bounds on search time and costs are what make this practical - real autonomous systems need guarantees, not just asymptotic optimality. It&#x27;s the kind of work that bridges the gap between beautiful mathematical theory and messy real-world robotics!</p></div><div class="network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200"><div class="prose prose-lg prose-slate max-w-none prose-headings:gradient-text prose-h1:text-4xl prose-h2:text-3xl prose-h3:text-2xl prose-h4:text-xl prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline"><div><!-- # Bandit-based multi-agent search under noisy observations -->
<h2>Problem Motivation</h2>
<p>Autonomous search missions using teams of multiple agents face several critical challenges:</p>
<ol>
<li><strong>Time Efficiency</strong>: Minimizing the time to identify interesting areas in large search environments</li>
<li><strong>Resource Constraints</strong>: Managing costs and energy usage during agent movement and sensing</li>
<li><strong>Sensor Limitations</strong>: Dealing with noise from low-cost, lightweight sensors typically used in autonomous systems</li>
<li><strong>Coordination Complexity</strong>: Developing tractable coordination strategies that scale with team size</li>
</ol>
<h2>Technical Approach</h2>
<h3>Thresholding Multi-Armed Bandits Framework</h3>
<p>The paper leverages the <strong>thresholding multi-armed bandits</strong> paradigm, which is particularly well-suited for search applications because:</p>
<ul>
<li><strong>Goal-Oriented</strong>: Instead of finding the single best location, agents seek areas above a quality threshold</li>
<li><strong>Practical</strong>: Reflects real-world search objectives where "good enough" locations are valuable</li>
<li><strong>Efficient</strong>: Reduces sample complexity compared to pure exploration approaches</li>
</ul>
<h3>Multi-Agent Coordination Strategy</h3>
<p>The proposed algorithm addresses coordination through:</p>
<ul>
<li><strong>Data-Driven Decisions</strong>: Uses observed data to guide agent movements and sensing actions</li>
<li><strong>Distributed Intelligence</strong>: Enables agents to make autonomous decisions while maintaining coordination</li>
<li><strong>Noise Resilience</strong>: Incorporates uncertainty quantification to handle sensor noise</li>
</ul>
<h2>Key Theoretical Contributions</h2>
<h3>1. Finite Upper Bounds</h3>
<p>The algorithm provides <strong>guaranteed finite upper bounds</strong> on:</p>
<ul>
<li><strong>Total search completion time</strong></li>
<li><strong>Time to label all interesting cells</strong></li>
<li><strong>Economic costs incurred during the search</strong></li>
</ul>
<h3>2. Performance Guarantees</h3>
<ul>
<li><strong>Tractable Coordination</strong>: Polynomial-time coordination strategies that scale with team size</li>
<li><strong>Noise Robustness</strong>: Provable performance even under noisy sensor observations</li>
<li><strong>Resource Efficiency</strong>: Bounds on energy consumption and movement costs</li>
</ul>
<h2>Algorithmic Innovation</h2>
<h3>Multi-Agent Bandit Framework</h3>
<ul>
<li><strong>Parallel Exploration</strong>: Multiple agents simultaneously explore different regions</li>
<li><strong>Information Sharing</strong>: Agents leverage shared observations to improve collective performance</li>
<li><strong>Adaptive Allocation</strong>: Dynamic assignment of agents to promising search areas</li>
</ul>
<h3>Noise Handling</h3>
<ul>
<li><strong>Uncertainty Quantification</strong>: Explicit modeling of sensor noise and observation uncertainty</li>
<li><strong>Robust Decision Making</strong>: Algorithms that maintain performance under noisy conditions</li>
<li><strong>Confidence-Based Actions</strong>: Decisions based on confidence intervals rather than point estimates</li>
</ul>
<h2>Applications and Impact</h2>
<h3>Autonomous Robotics</h3>
<ul>
<li><strong>Search and Rescue</strong>: Coordinated teams searching for survivors or targets</li>
<li><strong>Environmental Monitoring</strong>: Multi-robot systems monitoring pollution, wildlife, or weather</li>
<li><strong>Exploration Missions</strong>: Planetary rovers or underwater vehicles exploring unknown terrain</li>
</ul>
<h3>Practical Advantages</h3>
<ul>
<li><strong>Low-Cost Sensors</strong>: Algorithm designed for real-world sensor limitations</li>
<li><strong>Energy Efficiency</strong>: Explicit consideration of movement and sensing costs</li>
<li><strong>Scalable Teams</strong>: Coordination strategies that work with varying team sizes</li>
</ul>
<h2>Technical Significance</h2>
<p>This work bridges several important research areas:</p>
<ul>
<li><strong>Multi-Armed Bandits</strong>: Extending bandit theory to multi-agent scenarios</li>
<li><strong>Autonomous Systems</strong>: Providing theoretical foundations for practical deployment</li>
<li><strong>Distributed Decision Making</strong>: Developing coordination mechanisms with performance guarantees</li>
</ul>
<h2>Real-World Relevance</h2>
<p>The emphasis on <strong>noisy observations</strong> and <strong>cost constraints</strong> makes this work particularly relevant for practical deployment. Unlike many theoretical works that assume perfect sensors and unlimited resources, this paper explicitly addresses the limitations that autonomous systems face in real environments.</p>
<p>The <strong>finite upper bounds</strong> are crucial for mission planning and safety-critical applications where teams need guarantees on search completion times and resource usage.</p>
<h2>Future Directions</h2>
<p>This framework opens several avenues for future research:</p>
<ul>
<li>Extension to dynamic environments where interesting areas may change over time</li>
<li>Integration with path planning and obstacle avoidance for realistic deployment scenarios</li>
<li>Adaptation to heterogeneous teams with agents having different sensing capabilities</li>
</ul></div></div></div></div></div><!--$--><!--/$--><script src="/_next/static/chunks/webpack-a9151074ccb83ac8.js" async=""></script><script>(self.__next_f=self.__next_f||[]).push([0])</script><script>self.__next_f.push([1,"1:\"$Sreact.fragment\"\n2:I[7555,[],\"\"]\n3:I[1295,[],\"\"]\n5:I[9665,[],\"OutletBoundary\"]\n8:I[4911,[],\"AsyncMetadataOutlet\"]\na:I[9665,[],\"ViewportBoundary\"]\nc:I[9665,[],\"MetadataBoundary\"]\ne:I[6614,[],\"\"]\n:HL[\"/_next/static/media/39b0e861c537f507-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/media/e4af272ccee01ff0-s.p.woff2\",\"font\",{\"crossOrigin\":\"\",\"type\":\"font/woff2\"}]\n:HL[\"/_next/static/css/6801a04e29283989.css\",\"style\"]\n:HL[\"/_next/static/css/c7863c883e44cb4e.css\",\"style\"]\n"])</script><script>self.__next_f.push([1,"0:{\"P\":null,\"b\":\"0WWV71yL9vL6kq6l3xd7p\",\"p\":\"\",\"c\":[\"\",\"papers\",\"bandit-based-multi-agent-search-noisy-observations\",\"\"],\"i\":false,\"f\":[[[\"\",{\"children\":[\"papers\",{\"children\":[[\"slug\",\"bandit-based-multi-agent-search-noisy-observations\",\"d\"],{\"children\":[\"__PAGE__\",{}]}]}]},\"$undefined\",\"$undefined\",true],[\"\",[\"$\",\"$1\",\"c\",{\"children\":[[[\"$\",\"link\",\"0\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/6801a04e29283989.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}],[\"$\",\"link\",\"1\",{\"rel\":\"stylesheet\",\"href\":\"/_next/static/css/c7863c883e44cb4e.css\",\"precedence\":\"next\",\"crossOrigin\":\"$undefined\",\"nonce\":\"$undefined\"}]],[\"$\",\"html\",null,{\"lang\":\"en\",\"children\":[[\"$\",\"head\",null,{\"children\":[\"$\",\"script\",null,{\"type\":\"application/ld+json\",\"dangerouslySetInnerHTML\":{\"__html\":\"{\\\"@context\\\":\\\"https://schema.org\\\",\\\"@type\\\":\\\"Person\\\",\\\"name\\\":\\\"Parth K. Thaker\\\",\\\"jobTitle\\\":\\\"AI Research Engineer\\\",\\\"worksFor\\\":{\\\"@type\\\":\\\"Organization\\\",\\\"name\\\":\\\"Intuitive Surgical\\\",\\\"url\\\":\\\"https://www.intuitive.com\\\"},\\\"alumniOf\\\":[{\\\"@type\\\":\\\"EducationalOrganization\\\",\\\"name\\\":\\\"Arizona State University\\\",\\\"url\\\":\\\"https://www.asu.edu\\\"},{\\\"@type\\\":\\\"EducationalOrganization\\\",\\\"name\\\":\\\"Indian Institute of Technology Madras\\\",\\\"url\\\":\\\"https://www.iitm.ac.in\\\"}],\\\"url\\\":\\\"https://parththaker.github.io\\\",\\\"image\\\":\\\"https://parththaker.github.io/profile_photo.png\\\",\\\"sameAs\\\":[\\\"https://www.linkedin.com/in/parththaker1/\\\",\\\"https://twitter.com/ParthKThaker\\\",\\\"https://github.com/parththaker\\\"],\\\"knowsAbout\\\":[\\\"Graph Theory\\\",\\\"Nonconvex Optimization\\\",\\\"Bandit Learning\\\",\\\"Reinforcement Learning\\\",\\\"Machine Learning\\\",\\\"Artificial Intelligence\\\",\\\"Electrical Engineering\\\"],\\\"hasCredential\\\":{\\\"@type\\\":\\\"EducationalOccupationalCredential\\\",\\\"name\\\":\\\"Ph.D. in Electrical Engineering\\\",\\\"credentialCategory\\\":\\\"degree\\\"}}\"}}]}],[\"$\",\"body\",null,{\"className\":\"__variable_e8ce0c __variable_96cdd1 antialiased font-sans\",\"children\":[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":[[[\"$\",\"title\",null,{\"children\":\"404: This page could not be found.\"}],[\"$\",\"div\",null,{\"style\":{\"fontFamily\":\"system-ui,\\\"Segoe UI\\\",Roboto,Helvetica,Arial,sans-serif,\\\"Apple Color Emoji\\\",\\\"Segoe UI Emoji\\\"\",\"height\":\"100vh\",\"textAlign\":\"center\",\"display\":\"flex\",\"flexDirection\":\"column\",\"alignItems\":\"center\",\"justifyContent\":\"center\"},\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"style\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"body{color:#000;background:#fff;margin:0}.next-error-h1{border-right:1px solid rgba(0,0,0,.3)}@media (prefers-color-scheme:dark){body{color:#fff;background:#000}.next-error-h1{border-right:1px solid rgba(255,255,255,.3)}}\"}}],[\"$\",\"h1\",null,{\"className\":\"next-error-h1\",\"style\":{\"display\":\"inline-block\",\"margin\":\"0 20px 0 0\",\"padding\":\"0 23px 0 0\",\"fontSize\":24,\"fontWeight\":500,\"verticalAlign\":\"top\",\"lineHeight\":\"49px\"},\"children\":404}],[\"$\",\"div\",null,{\"style\":{\"display\":\"inline-block\"},\"children\":[\"$\",\"h2\",null,{\"style\":{\"fontSize\":14,\"fontWeight\":400,\"lineHeight\":\"49px\",\"margin\":0},\"children\":\"This page could not be found.\"}]}]]}]}]],[]],\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]}]]}]]}],{\"children\":[\"papers\",[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[[\"slug\",\"bandit-based-multi-agent-search-noisy-observations\",\"d\"],[\"$\",\"$1\",\"c\",{\"children\":[null,[\"$\",\"$L2\",null,{\"parallelRouterKey\":\"children\",\"error\":\"$undefined\",\"errorStyles\":\"$undefined\",\"errorScripts\":\"$undefined\",\"template\":[\"$\",\"$L3\",null,{}],\"templateStyles\":\"$undefined\",\"templateScripts\":\"$undefined\",\"notFound\":\"$undefined\",\"forbidden\":\"$undefined\",\"unauthorized\":\"$undefined\"}]]}],{\"children\":[\"__PAGE__\",[\"$\",\"$1\",\"c\",{\"children\":[\"$L4\",null,[\"$\",\"$L5\",null,{\"children\":[\"$L6\",\"$L7\",[\"$\",\"$L8\",null,{\"promise\":\"$@9\"}]]}]]}],{},null,false]},null,false]},null,false]},null,false],[\"$\",\"$1\",\"h\",{\"children\":[null,[\"$\",\"$1\",\"8XyXhhj8td1pR8MgCcH5uv\",{\"children\":[[\"$\",\"$La\",null,{\"children\":\"$Lb\"}],[\"$\",\"meta\",null,{\"name\":\"next-size-adjust\",\"content\":\"\"}]]}],[\"$\",\"$Lc\",null,{\"children\":\"$Ld\"}]]}],false]],\"m\":\"$undefined\",\"G\":[\"$e\",\"$undefined\"],\"s\":false,\"S\":true}\n"])</script><script>self.__next_f.push([1,"f:\"$Sreact.suspense\"\n10:I[4911,[],\"AsyncMetadata\"]\nd:[\"$\",\"div\",null,{\"hidden\":true,\"children\":[\"$\",\"$f\",null,{\"fallback\":null,\"children\":[\"$\",\"$L10\",null,{\"promise\":\"$@11\"}]}]}]\n7:null\n"])</script><script>self.__next_f.push([1,"12:I[8694,[\"729\",\"static/chunks/729-0ae0020d02b338de.js\",\"63\",\"static/chunks/63-604b46d13fd30a34.js\",\"248\",\"static/chunks/app/papers/%5Bslug%5D/page-7d3e6ccfb45e5478.js\"],\"default\"]\n13:I[449,[\"729\",\"static/chunks/729-0ae0020d02b338de.js\",\"63\",\"static/chunks/63-604b46d13fd30a34.js\",\"248\",\"static/chunks/app/papers/%5Bslug%5D/page-7d3e6ccfb45e5478.js\"],\"default\"]\n14:I[6874,[\"729\",\"static/chunks/729-0ae0020d02b338de.js\",\"63\",\"static/chunks/63-604b46d13fd30a34.js\",\"248\",\"static/chunks/app/papers/%5Bslug%5D/page-7d3e6ccfb45e5478.js\"],\"\"]\n15:T14ee,"])</script><script>self.__next_f.push([1,"\u003c!-- # Bandit-based multi-agent search under noisy observations --\u003e\n\u003ch2\u003eProblem Motivation\u003c/h2\u003e\n\u003cp\u003eAutonomous search missions using teams of multiple agents face several critical challenges:\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003cstrong\u003eTime Efficiency\u003c/strong\u003e: Minimizing the time to identify interesting areas in large search environments\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eResource Constraints\u003c/strong\u003e: Managing costs and energy usage during agent movement and sensing\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSensor Limitations\u003c/strong\u003e: Dealing with noise from low-cost, lightweight sensors typically used in autonomous systems\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eCoordination Complexity\u003c/strong\u003e: Developing tractable coordination strategies that scale with team size\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch2\u003eTechnical Approach\u003c/h2\u003e\n\u003ch3\u003eThresholding Multi-Armed Bandits Framework\u003c/h3\u003e\n\u003cp\u003eThe paper leverages the \u003cstrong\u003ethresholding multi-armed bandits\u003c/strong\u003e paradigm, which is particularly well-suited for search applications because:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eGoal-Oriented\u003c/strong\u003e: Instead of finding the single best location, agents seek areas above a quality threshold\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003ePractical\u003c/strong\u003e: Reflects real-world search objectives where \"good enough\" locations are valuable\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEfficient\u003c/strong\u003e: Reduces sample complexity compared to pure exploration approaches\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eMulti-Agent Coordination Strategy\u003c/h3\u003e\n\u003cp\u003eThe proposed algorithm addresses coordination through:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eData-Driven Decisions\u003c/strong\u003e: Uses observed data to guide agent movements and sensing actions\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDistributed Intelligence\u003c/strong\u003e: Enables agents to make autonomous decisions while maintaining coordination\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNoise Resilience\u003c/strong\u003e: Incorporates uncertainty quantification to handle sensor noise\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eKey Theoretical Contributions\u003c/h2\u003e\n\u003ch3\u003e1. Finite Upper Bounds\u003c/h3\u003e\n\u003cp\u003eThe algorithm provides \u003cstrong\u003eguaranteed finite upper bounds\u003c/strong\u003e on:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTotal search completion time\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eTime to label all interesting cells\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEconomic costs incurred during the search\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003e2. Performance Guarantees\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eTractable Coordination\u003c/strong\u003e: Polynomial-time coordination strategies that scale with team size\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNoise Robustness\u003c/strong\u003e: Provable performance even under noisy sensor observations\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eResource Efficiency\u003c/strong\u003e: Bounds on energy consumption and movement costs\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eAlgorithmic Innovation\u003c/h2\u003e\n\u003ch3\u003eMulti-Agent Bandit Framework\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eParallel Exploration\u003c/strong\u003e: Multiple agents simultaneously explore different regions\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInformation Sharing\u003c/strong\u003e: Agents leverage shared observations to improve collective performance\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAdaptive Allocation\u003c/strong\u003e: Dynamic assignment of agents to promising search areas\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003eNoise Handling\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eUncertainty Quantification\u003c/strong\u003e: Explicit modeling of sensor noise and observation uncertainty\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eRobust Decision Making\u003c/strong\u003e: Algorithms that maintain performance under noisy conditions\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eConfidence-Based Actions\u003c/strong\u003e: Decisions based on confidence intervals rather than point estimates\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eApplications and Impact\u003c/h2\u003e\n\u003ch3\u003eAutonomous Robotics\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eSearch and Rescue\u003c/strong\u003e: Coordinated teams searching for survivors or targets\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEnvironmental Monitoring\u003c/strong\u003e: Multi-robot systems monitoring pollution, wildlife, or weather\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eExploration Missions\u003c/strong\u003e: Planetary rovers or underwater vehicles exploring unknown terrain\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3\u003ePractical Advantages\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eLow-Cost Sensors\u003c/strong\u003e: Algorithm designed for real-world sensor limitations\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEnergy Efficiency\u003c/strong\u003e: Explicit consideration of movement and sensing costs\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eScalable Teams\u003c/strong\u003e: Coordination strategies that work with varying team sizes\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eTechnical Significance\u003c/h2\u003e\n\u003cp\u003eThis work bridges several important research areas:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMulti-Armed Bandits\u003c/strong\u003e: Extending bandit theory to multi-agent scenarios\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAutonomous Systems\u003c/strong\u003e: Providing theoretical foundations for practical deployment\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eDistributed Decision Making\u003c/strong\u003e: Developing coordination mechanisms with performance guarantees\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2\u003eReal-World Relevance\u003c/h2\u003e\n\u003cp\u003eThe emphasis on \u003cstrong\u003enoisy observations\u003c/strong\u003e and \u003cstrong\u003ecost constraints\u003c/strong\u003e makes this work particularly relevant for practical deployment. Unlike many theoretical works that assume perfect sensors and unlimited resources, this paper explicitly addresses the limitations that autonomous systems face in real environments.\u003c/p\u003e\n\u003cp\u003eThe \u003cstrong\u003efinite upper bounds\u003c/strong\u003e are crucial for mission planning and safety-critical applications where teams need guarantees on search completion times and resource usage.\u003c/p\u003e\n\u003ch2\u003eFuture Directions\u003c/h2\u003e\n\u003cp\u003eThis framework opens several avenues for future research:\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eExtension to dynamic environments where interesting areas may change over time\u003c/li\u003e\n\u003cli\u003eIntegration with path planning and obstacle avoidance for realistic deployment scenarios\u003c/li\u003e\n\u003cli\u003eAdaptation to heterogeneous teams with agents having different sensing capabilities\u003c/li\u003e\n\u003c/ul\u003e"])</script><script>self.__next_f.push([1,"4:[\"$\",\"div\",null,{\"className\":\"min-h-screen relative bg-gradient-to-br from-slate-50 via-blue-50 to-indigo-50\",\"children\":[[\"$\",\"$L12\",null,{}],[\"$\",\"$L13\",null,{}],[\"$\",\"nav\",null,{\"className\":\"relative z-50 border-b border-slate-200/50 bg-white/80 backdrop-blur-md sticky top-0\",\"children\":[\"$\",\"div\",null,{\"className\":\"max-w-7xl mx-auto px-6 py-4\",\"children\":[\"$\",\"div\",null,{\"className\":\"flex justify-between items-center\",\"children\":[[\"$\",\"$L14\",null,{\"href\":\"/\",\"className\":\"text-2xl font-bold gradient-text\",\"children\":\"Parth K. Thaker\"}],[\"$\",\"div\",null,{\"className\":\"flex gap-8\",\"children\":[[\"$\",\"$L14\",null,{\"href\":\"/papers\",\"className\":\"relative group\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-blue-600 font-medium\",\"children\":\"Papers\"}],[\"$\",\"div\",null,{\"className\":\"absolute -bottom-1 left-0 w-full h-0.5 bg-gradient-to-r from-blue-500 to-indigo-500\"}]]}],[\"$\",\"$L14\",null,{\"href\":\"/blogs\",\"className\":\"relative group\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-slate-700 hover:text-orange-600 transition-colors duration-300 font-medium\",\"children\":\"Blog\"}],[\"$\",\"div\",null,{\"className\":\"absolute -bottom-1 left-0 w-0 h-0.5 bg-gradient-to-r from-orange-500 to-red-500 group-hover:w-full transition-all duration-300\"}]]}],[\"$\",\"$L14\",null,{\"href\":\"/hobbies\",\"className\":\"relative group\",\"children\":[[\"$\",\"span\",null,{\"className\":\"text-slate-700 hover:text-green-600 transition-colors duration-300 font-medium\",\"children\":\"Hobbies\"}],[\"$\",\"div\",null,{\"className\":\"absolute -bottom-1 left-0 w-0 h-0.5 bg-gradient-to-r from-green-500 to-emerald-500 group-hover:w-full transition-all duration-300\"}]]}]]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"relative z-10 max-w-5xl mx-auto px-6 py-12\",\"children\":[[\"$\",\"div\",null,{\"className\":\"network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200 mb-8\",\"children\":[\"$\",\"div\",null,{\"className\":\"space-y-6\",\"children\":[\"$\",\"div\",null,{\"children\":[[\"$\",\"h1\",null,{\"className\":\"text-4xl font-bold gradient-text mb-4\",\"children\":\"Bandit-based multi-agent search under noisy observations\"}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap items-center gap-x-6 gap-y-2 mb-6 text-sm\",\"children\":[[\"$\",\"div\",null,{\"className\":\"text-slate-500\",\"children\":\"P Thaker, S Di Cairano, A P Vinod\"}],[\"$\",\"div\",null,{\"className\":\"text-slate-500\",\"children\":\"June 2023\"}],[\"$\",\"div\",null,{\"className\":\"text-slate-500\",\"children\":\"IFAC 2023\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-2 mb-6\",\"children\":[[\"$\",\"span\",\"Multi-armed Bandits\",{\"className\":\"px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium\",\"children\":\"Multi-armed Bandits\"}],[\"$\",\"span\",\"Multi-agent Systems\",{\"className\":\"px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium\",\"children\":\"Multi-agent Systems\"}],[\"$\",\"span\",\"Autonomous Search\",{\"className\":\"px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium\",\"children\":\"Autonomous Search\"}],[\"$\",\"span\",\"Robotics\",{\"className\":\"px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium\",\"children\":\"Robotics\"}],[\"$\",\"span\",\"Noise Robustness\",{\"className\":\"px-4 py-2 bg-gradient-to-r from-blue-50 to-indigo-50 border border-blue-200 text-blue-700 rounded-full text-sm font-medium\",\"children\":\"Noise Robustness\"}]]}],[\"$\",\"div\",null,{\"className\":\"flex flex-wrap gap-4 pt-4 border-t border-slate-200\",\"children\":[\"$undefined\",[\"$\",\"a\",null,{\"href\":\"https://doi.org/10.1016/j.ifacol.2023.10.1377\",\"className\":\"flex items-center gap-2 text-blue-600 hover:text-blue-700 font-medium transition-colors\",\"target\":\"_blank\",\"rel\":\"noopener noreferrer\",\"children\":[[\"$\",\"div\",null,{\"className\":\"w-2 h-2 bg-blue-500 rounded-full\"}],\"DOI\"]}],\"$undefined\",\"$undefined\",\"$undefined\",\"$undefined\"]}]]}]}]}],[\"$\",\"div\",null,{\"className\":\"network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200 mb-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold gradient-text mb-4\",\"children\":\"Abstract\"}],[\"$\",\"p\",null,{\"className\":\"text-slate-700 leading-relaxed text-lg\",\"children\":\"We address autonomous search using teams of multiple agents, requiring tractable coordination strategies that can lower the time to identify interesting areas in the search environment, lower the costs/energy usage by the search agents during movement and sensing, and be resilient to the noise present in the sensed data due to the use of low-cost and low-weight sensors. We propose a data-driven, multi-agent search algorithm to achieve these goals using the framework of thresholding multi-armed bandits. The algorithm includes finite upper bounds on the time taken to complete the search, on the time taken to label all interesting cells, and on the economic costs incurred during the search.\"}]]}],[\"$\",\"div\",null,{\"className\":\"network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200 mb-8\",\"children\":[[\"$\",\"h2\",null,{\"className\":\"text-2xl font-bold gradient-text mb-4\",\"children\":\"What Excited Me\"}],[\"$\",\"p\",null,{\"className\":\"text-slate-700 leading-relaxed text-lg\",\"children\":\"This paper hits the sweet spot between theory and practice that I absolutely love! What excites me most is how it tackles real-world constraints that make autonomous systems actually deployable - noisy sensors, energy budgets, and coordination overhead. The genius lies in translating the classical multi-armed bandit framework to handle multiple agents simultaneously searching under uncertainty. The thresholding approach is particularly clever because it reflects how search missions actually work: you don't need to find the absolute best locations, just ones that are 'good enough' above some threshold. The finite upper bounds on search time and costs are what make this practical - real autonomous systems need guarantees, not just asymptotic optimality. It's the kind of work that bridges the gap between beautiful mathematical theory and messy real-world robotics!\"}]]}],\"$undefined\",\"$undefined\",[\"$\",\"div\",null,{\"className\":\"network-card p-8 rounded-2xl bg-white/80 backdrop-blur-sm border border-slate-200\",\"children\":[\"$\",\"div\",null,{\"className\":\"prose prose-lg prose-slate max-w-none prose-headings:gradient-text prose-h1:text-4xl prose-h2:text-3xl prose-h3:text-2xl prose-h4:text-xl prose-a:text-blue-600 prose-a:no-underline hover:prose-a:underline\",\"children\":[\"$\",\"div\",null,{\"dangerouslySetInnerHTML\":{\"__html\":\"$15\"}}]}]}]]}]]}]\n"])</script><script>self.__next_f.push([1,"b:[[\"$\",\"meta\",\"0\",{\"charSet\":\"utf-8\"}],[\"$\",\"meta\",\"1\",{\"name\":\"viewport\",\"content\":\"width=device-width, initial-scale=1\"}]]\n6:null\n"])</script><script>self.__next_f.push([1,"9:{\"metadata\":[[\"$\",\"title\",\"0\",{\"children\":\"Parth K. Thaker - AI Research Engineer | Graph Theory \u0026 Optimization\"}],[\"$\",\"meta\",\"1\",{\"name\":\"description\",\"content\":\"AI Research Engineer at Intuitive Surgical. Ph.D. in Electrical Engineering from ASU. Specializing in nonconvex optimization, graph theory, bandit learning, and secure LLM workflows.\"}],[\"$\",\"meta\",\"2\",{\"name\":\"author\",\"content\":\"Parth K. Thaker\"}],[\"$\",\"meta\",\"3\",{\"name\":\"keywords\",\"content\":\"Parth Thaker,AI Research Engineer,Graph Theory,Nonconvex Optimization,Bandit Learning,Reinforcement Learning,Machine Learning,Intuitive Surgical,Arizona State University,ASU,IIT Madras,Electrical Engineering,LLM,Secure AI,Research Portfolio\"}],[\"$\",\"meta\",\"4\",{\"name\":\"creator\",\"content\":\"Parth K. Thaker\"}],[\"$\",\"meta\",\"5\",{\"name\":\"publisher\",\"content\":\"Parth K. Thaker\"}],[\"$\",\"meta\",\"6\",{\"name\":\"robots\",\"content\":\"index, follow\"}],[\"$\",\"meta\",\"7\",{\"name\":\"googlebot\",\"content\":\"index, follow, max-video-preview:-1, max-image-preview:large, max-snippet:-1\"}],[\"$\",\"link\",\"8\",{\"rel\":\"canonical\",\"href\":\"https://parththaker.github.io/\"}],[\"$\",\"meta\",\"9\",{\"name\":\"google-site-verification\",\"content\":\"vR0MHUqGDsFvNBkYnX5muEopmvKabsrcthb-7WDj6nI\"}],[\"$\",\"meta\",\"10\",{\"property\":\"og:title\",\"content\":\"Parth K. Thaker - AI Research Engineer | Graph Theory \u0026 Optimization\"}],[\"$\",\"meta\",\"11\",{\"property\":\"og:description\",\"content\":\"AI Research Engineer at Intuitive Surgical. Ph.D. in Electrical Engineering from ASU. Specializing in nonconvex optimization, graph theory, bandit learning, and secure LLM workflows.\"}],[\"$\",\"meta\",\"12\",{\"property\":\"og:url\",\"content\":\"https://parththaker.github.io/\"}],[\"$\",\"meta\",\"13\",{\"property\":\"og:site_name\",\"content\":\"Parth K. Thaker\"}],[\"$\",\"meta\",\"14\",{\"property\":\"og:locale\",\"content\":\"en_US\"}],[\"$\",\"meta\",\"15\",{\"property\":\"og:image\",\"content\":\"https://parththaker.github.io/profile_photo.png\"}],[\"$\",\"meta\",\"16\",{\"property\":\"og:image:width\",\"content\":\"1200\"}],[\"$\",\"meta\",\"17\",{\"property\":\"og:image:height\",\"content\":\"630\"}],[\"$\",\"meta\",\"18\",{\"property\":\"og:image:alt\",\"content\":\"Parth K. Thaker - AI Research Engineer\"}],[\"$\",\"meta\",\"19\",{\"property\":\"og:type\",\"content\":\"website\"}],[\"$\",\"meta\",\"20\",{\"name\":\"twitter:card\",\"content\":\"summary_large_image\"}],[\"$\",\"meta\",\"21\",{\"name\":\"twitter:creator\",\"content\":\"@ParthKThaker\"}],[\"$\",\"meta\",\"22\",{\"name\":\"twitter:title\",\"content\":\"Parth K. Thaker - AI Research Engineer | Graph Theory \u0026 Optimization\"}],[\"$\",\"meta\",\"23\",{\"name\":\"twitter:description\",\"content\":\"AI Research Engineer at Intuitive Surgical. Ph.D. in Electrical Engineering from ASU. Specializing in nonconvex optimization, graph theory, bandit learning, and secure LLM workflows.\"}],[\"$\",\"meta\",\"24\",{\"name\":\"twitter:image\",\"content\":\"https://parththaker.github.io/profile_photo.png\"}],[\"$\",\"link\",\"25\",{\"rel\":\"icon\",\"href\":\"/favicon.ico\",\"type\":\"image/x-icon\",\"sizes\":\"16x16\"}]],\"error\":null,\"digest\":\"$undefined\"}\n"])</script><script>self.__next_f.push([1,"11:{\"metadata\":\"$9:metadata\",\"error\":null,\"digest\":\"$undefined\"}\n"])</script></body></html>