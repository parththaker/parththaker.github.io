<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.37.1" />
  <meta name="author" content="Parth Thaker">
  <meta name="description" content="PhD Student">

  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="/css/highlight.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.0/css/academicons.min.css" integrity="sha512-GGGNUPDhnG8LEAEDsjqYIQns+Gu8RBs4j5XGlxl7UfRaZBhCCm5jenJkeJL8uPuOXGqgl8/H1gjlWQDRjd3cUQ==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather%7CRoboto+Mono">
  <link rel="stylesheet" href="/css/hugo-academic.css">
  

  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-101739895-1', 'auto');
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  

  <link rel="alternate" href="https://parththaker.github.io/index.xml" type="application/rss+xml" title="Parth Thaker">
  <link rel="feed" href="https://parththaker.github.io/index.xml" type="application/rss+xml" title="Parth Thaker">

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="https://parththaker.github.io/post/skipping-projection/">

  

  <title>Skippings in projected gradient descent | Parth Thaker</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Parth Thaker</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#publications">
            
            <span>Publications</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/support_docs/resume.pdf">
            
            <span>CV</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
          </a>
        </li>

        
        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  


  <div class="article-container">
    <h1 itemprop="name">Skippings in projected gradient descent</h1>
    

<div class="article-metadata">

  <span class="article-date">
    <time datetime="2018-05-01 12:00:00 &#43;0000 UTC" itemprop="datePublished">
      Tue, May 1, 2018
    </time>
  </span>

  

  
  
  
  <span class="article-tags">
    <i class="fa fa-tags"></i>
    
    <a href="/tags/projected-gradient-descent">projected gradient descent</a
    >
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fparththaker.github.io%2fpost%2fskipping-projection%2f"
         target="_blank">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=Skippings%20in%20projected%20gradient%20descent&amp;url=https%3a%2f%2fparththaker.github.io%2fpost%2fskipping-projection%2f"
         target="_blank">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fparththaker.github.io%2fpost%2fskipping-projection%2f&amp;title=Skippings%20in%20projected%20gradient%20descent"
         target="_blank">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fparththaker.github.io%2fpost%2fskipping-projection%2f&amp;title=Skippings%20in%20projected%20gradient%20descent"
         target="_blank">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=Skippings%20in%20projected%20gradient%20descent&amp;body=https%3a%2f%2fparththaker.github.io%2fpost%2fskipping-projection%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

    <div class="article-style" itemprop="articleBody">
      

<p>I was sitting in a guest lecture of <a href="http://people.cs.umass.edu/~mahadeva/Site/About_Me.html" target="_blank">Prof. Shankar Mahadevan</a> from University of Massachusettes when he had come to my undergrad univ IIT Madras, where
he was talking about his (at that time) <a href="https://arxiv.org/pdf/1405.6757v1.pdf" target="_blank">recent work</a> with his studnet Ian Gemp.
He was stating intoduction of variational inequalties to a relatively clueless audience, introducing the age old methods of extragradient methods, etc.</p>

<p>In the middle he said somehtign which pinged my interest.
He was saying about how <a href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods" target="_blank">Ruunge-Kutta methods</a> method when used in Reinforcement learning to their problem seems to go on being more faster adn faster as we had mroe skippings/ more terms we were considering.
THis was followed by a quesiton &ldquo;So how far can we keep including these terms?&rdquo;</p>

<p>This seemed sort of surreal to me. A system which just keeps accelerating towards perfection ? This needed more investigation.</p>

<h2 id="glimpse-of-ruunge-kutta">Glimpse of Ruunge_kutta</h2>

<p>Runge-Kutta method used to find approximate solutions in Ordinary Differential Equations seemed a lot close to the form of equations I was getting. (Maybe it&rsquo;s the same &hellip; and this all is obvious thing&hellip; Not sure)\</p>

<p>A General Runge-Kutta Gradient descent looks like,</p>

<p>$$\begin{equation}k_1 = \alpha   \nabla F(x_k)\end{equation}$$
$$\begin{equation}k_2 = \alpha \nabla F(x_k - a_{21}k_1)\end{equation}$$
$$\begin{equation}k_3 = \alpha \nabla F(x_k - a_{31}k_1 - a_{32}k_2)\end{equation}$$</p>

<p>So for general term,</p>

<p>$$\begin{equation}k_s = \alpha \nabla F(x_k - a_{s1}k_1 - a_{s2}k_2 - \dots - a_{s,s-1}k_{s-1})\end{equation}$$</p>

<p>The next iterate $x_k$ in the sequence of the algorithm as,</p>

<p>$$\begin{equation}x_{k+1} = x_{k} - \sum_{i=1}^sb_i k_i\end{equation}$$</p>

<h2 id="constrained-convex-optimization">Constrained Convex Optimization</h2>

<p>A simple constrained Optimization problem can be stated as,
$$\begin{equation}
\min\ \ \ f(x)\ \ \ \  \text{over}\ \ \ \  x\in \chi
\end{equation}$$</p>

<p>where $f(x)$ is a doubly differentiable convex function. The normal gradient descent considering the steepest descent criteria would involve the following update equation,</p>

<p>$$\begin{equation}
x_{k+1} = x_{k} - \eta\nabla f(x_k)
\end{equation}$$</p>

<p>Since the next iterative point $x_{k+1}$ needs to belong to the constrained set $\chi$, we have the Projection step as,</p>

<p>$$\begin{equation}
x_{k+1} = P_{\chi}(x_{k} - \eta\nabla f(x_k))
\end{equation}$$</p>

<p>where the projection operator $P_{\chi}(x)$ is defined as,
$$\begin{equation}
P_{\chi}(x) = \arg\min_{y\in \chi}||x-y||^2
\end{equation}$$</p>

<h3 id="what-problem-are-we-looking-at-here">What problem are we looking at here?</h3>

<p>In many constrained optimization problems, one of the major computation issue with projected gradient descent is computing the Projection of a candidate variable $x_k$.
Hence, I am trying to reduce the total number of Projection computations required for the algorithm to converge.</p>

<h2 id="solution">Solution?</h2>

<p>Taking the motivation from Ruunge-Kutta logic, consider the following iterations where we take projections on alternate steps as shown below. (I am calling it 2-step skip projection),
$$\begin{equation}
y_{k+1} = x_{k} - \eta_1\nabla f(x_{k})\end{equation}$$</p>

<p>$$\begin{equation}
x_{k+1} = P_{\chi}(y_{k+1}-\eta_2\nabla f(y_{k+1}))\end{equation}$$</p>

<p>Similarly, we can consider a 3-step skip projection as well,
$$\begin{equation}
y_{k+1} = x_{k} - \eta_1\nabla f(x_{k})\end{equation}$$</p>

<p>$$\begin{equation}
z_{k+1} = y_{k+1} - \eta_2\nabla f(y_{k+1})\end{equation}$$</p>

<p>$$\begin{equation}
x_{k+1} = P_{\chi}(z_{k+1}-\eta_3\nabla f(z_{k+1}))\end{equation}$$</p>

<p>We can keep increasing the number of skips. Plotting for a simple example,</p>

<p><img src="../../img/sk_proj_overview.png" alt=" Overview " /></p>

<p>Here the each point in the graph represents the $error(k) = \log (f(Pr(x_k)) - f(x^*))$.</p>

<p><img src="../../img/sk_proj_zoom.png" alt=" Zoom " /></p>

<h2 id="the-two-extremes">The two extremes</h2>

<p>The two extreme can be thought of as follows:
1) Standard Projected gradient descent</p>

<p>$$\begin{equation}
x_{k+1} = P_{\chi}(x_{k} - \eta\nabla f(x_k))
\end{equation}$$</p>

<p>2) Infinite step look ahead gradient descent</p>

<p>This extreme case of this skipping will be when we are projecting only after we reach the optimal point
$$\begin{equation}
y = \arg\min f(x)
\end{equation}$$</p>

<p>$$\begin{equation}
x^* = P_{\chi}(y)
\end{equation}$$</p>

<p>The problem with this being, the fixed point of both these cases ned not be the same and therein problem lies.</p>

<p>But this need not be the same as the fixed point of the iterative scheme,
$$\begin{equation}
x_{k+1} = P_{\chi}(x_{k} - \eta\nabla f(x_k))
\end{equation}$$</p>

<p>Thus the error between this two schemes is what we are seeing in the Figure 2.</p>

<h2 id="possibly-workaround">Possibly Workaround</h2>

<p>We can make $\eta$(stepsize) step dependent like $\frac{1}{k}$ which follows $\sum \eta_k = \infty$ and $\sum \eta^2 &lt; \infty$ which will again ensure that $error \rightarrow 0$ as $k \rightarrow \infty$.<br />
Using the same logic, I simulated it with the same functions as  previous plots. Results are as follows,</p>

<p><img src="../../img/sk_proj_decay.png" alt=" Zoom " /></p>

<h2 id="drawbacks">Drawbacks</h2>

<p>Even if this approach shows some change in the number of projections required, but this change wont be significant enough for a factor reduction.
There are no significant change in the convergence rate of this new proposed algorithm, and hence I dont think there is much hope for the idea to form a good enough innovation.</p>

<h2 id="license">License</h2>

<p>Copyright 2017 <a href="https://parththaker.github.io/" target="_blank">Parth Thaker</a>.</p>

<p>Released under the <a href="https://github.com/gcushen/hugo-academic/blob/master/LICENSE.md" target="_blank">MIT</a> license.</p>

    </div>
  </div>

</article>

<div class="container">
  <nav>
  <ul class="pager">
    
    <li class="previous"><a href="https://parththaker.github.io/post/chebyshev/"><span
      aria-hidden="true">&larr;</span> Basic look over Chebyshev Polynomials</a></li>
    

    
  </ul>
</nav>

</div>

<div class="article-container">
  

</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017 Parth Thaker &middot; 

      Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic
      theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.12.4/jquery.min.js" integrity="sha512-jGsMH83oKe9asCpkOVkBnUrDDTp8wl+adkB2D+//JtlxO4SrLoJdhbOysIFQJloQFD+C4Fl1rMsQZF76JjV0eQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.2/imagesloaded.pkgd.min.js" integrity="sha512-iHzEu7GbSc705hE2skyH6/AlTpOfBmkx7nUqTLGzPYR+C1tRaItbRlJ7hT/D3YQ9SV0fqLKzp4XY9wKulTBGTw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/TweenMax.min.js" integrity="sha512-Z5heTz36xTemt1TbtbfXtTq5lMfYnOkXM2/eWcTTiLU01+Sw4ku1i7vScDc8fWhrP2abz9GQzgKH5NGBLoYlAw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/plugins/ScrollToPlugin.min.js" integrity="sha512-CDeU7pRtkPX6XJtF/gcFWlEwyaX7mcAp5sO3VIu/ylsdR74wEw4wmBpD5yYTrmMAiAboi9thyBUr1vXRPA7t0Q==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>

      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

